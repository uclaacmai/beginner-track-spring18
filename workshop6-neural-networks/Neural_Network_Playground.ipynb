{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Playground.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "yryz3Nq1K7-L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network Playground\n",
        "\n",
        "<img src=\"http://nicolamanzini.com/wp-content/uploads/2017/11/single_hidden_layer.jpg\" />\n",
        "\n",
        "Neural networks have become increasingly important in almost all fields today. To help you get a better understanding of how different parameters can affect a neural network, we have created a few interactive exercises you can try below. "
      ]
    },
    {
      "metadata": {
        "id": "DJ8HBh9X1XCP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Packages\n",
        "\n",
        "The neural network we are going to use is implemented using Tensorflow, a very popular machine learning library."
      ]
    },
    {
      "metadata": {
        "id": "NF8aHIDpLqlI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xxA4ewp1cgF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "The data we are going to be training on is the MNIST handwritten digits dataset, a popular dataset for educational purposes. This dataset contains grayscale images of handwritten digits ranging from 0-9. Each image is 28x28. Along with each image is a one-hot encoded label."
      ]
    },
    {
      "metadata": {
        "id": "zjiiuBKZM8JL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "batch = mnist.train.next_batch(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5KDq6U-R2W1J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take a look at some images and their corresponding labels. Use the slider to look at any of 50 sample images."
      ]
    },
    {
      "metadata": {
        "id": "MzLaiXFV2b87",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Looking at the Data { run: \"auto\", vertical-output: true }\n",
        "image = 0 #@param {type:\"slider\", min:0, max:50, step:1}\n",
        "image *= image\n",
        "\n",
        "plt.figure(figsize = (14, 4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(mnist.train.images[image].reshape(28,28), cmap='gray')\n",
        "plt.title(np.argmax(mnist.train.labels[image]), size='xx-large')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nLabel: \" + str(mnist.train.labels[image]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TXsAGvdD6C3P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Go ahead and run the cell below to set up the model we will be using."
      ]
    },
    {
      "metadata": {
        "id": "2wALj5saM9XF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model(activation, num_units, num_it, lr, init):\n",
        "    activations = {\"sigmoid\": tf.nn.sigmoid, \"tanh\": tf.nn.tanh, \"ReLU\": tf.nn.relu}\n",
        "    initialize = tf.glorot_normal_initializer() if init else tf.zeros_initializer()\n",
        "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "    y = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "    hidden_layer = tf.layers.dense(x, num_units, activation=activations[activation], kernel_initializer=initialize)\n",
        "    output_layer = tf.layers.dense(hidden_layer, 10, kernel_initializer=initialize)\n",
        "\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_layer))\n",
        "\n",
        "    optimizer = tf.train.RMSPropOptimizer(lr).minimize(cost)\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for step in range(num_it):\n",
        "            _, val = sess.run([optimizer, cost], feed_dict={x: batch[0], y: batch[1]})\n",
        "            if num_it < 10 or step % int(num_it / 10) == 0:\n",
        "                print(\"cost at iteration: {}: {}\".format(step, val))\n",
        "\n",
        "        correct_pred = tf.equal(tf.argmax(output_layer,1), tf.argmax(y,1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(output_layer, axis=1), tf.argmax(y, axis=1)), tf.float32))\n",
        "        print((\"\\nAccuracy: {:.2f}\").format(accuracy.eval(feed_dict={x: mnist.train.images, y: mnist.train.labels}) * 100) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A1jCQrWW7HO1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Activation Functions\n",
        "\n",
        "Choosing a good activation function can help speed up training and make our model more accurate. The three functions we are going to look at are sigmoid, tanh and ReLU. Their equations and graphs are below.\n",
        "\n",
        "#### $sigmoid(z) = \\frac{1}{1+e^{-z}}$\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1200px-Logistic-curve.svg.png\" height=\"150px\"/>\n",
        "\n",
        "### $tanh(z) = \\frac{e^z-e^{-z}}{e^z+e^{-z}}$\n",
        "\n",
        "<img src=\"http://reference.wolfram.com/language/ref/Files/Tanh.en/O_2.png\" height=\"140px\" />\n",
        "\n",
        "#### $ReLU(z)=max( 0, z)$\n",
        "\n",
        "<img src=\"https://i.imgur.com/gKA4kA9.jpg\" height=\"150px\" />"
      ]
    },
    {
      "metadata": {
        "id": "1pgvEYbOEby3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Select one of the activation functions below and the model will automatically train!\n",
        "\n",
        "**Some Things to Note**\n",
        "- How does each activation affect the accuracy?\n",
        "- Is there a clear distinction in performance between them?"
      ]
    },
    {
      "metadata": {
        "id": "FI4AeZxqMDEz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title { run: \"auto\", vertical-output: true }\n",
        "clear_output()\n",
        "activation = \"sigmoid\" #@param [\"sigmoid\", \"tanh\", \"ReLU\"]\n",
        "\n",
        "model(activation, 100, 100, .001, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m0kC39MeFP3L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Number of Hidden Units (neurons)"
      ]
    },
    {
      "metadata": {
        "id": "NEVJVJDbOoZi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In our hidden layer, we can have a variable number of neurons. Each neuron is essentially just a logistic regression unit. The more units we add the more information we can store, but this also means we will need to do more computation. Tinker with different numbers of units (1-1000) and see how it affects our model.\n",
        "\n",
        "**Some Things to Note**\n",
        "- How does the number of units affect the accuracy of the model?\n",
        "    - Is it a linear relationship?\n",
        "- How does changing the number of units affect the time our model takes to train?\n",
        "- What is a possible problem you could see happening if we have too many units?\n",
        "    - Hint: think about what happens when a model fits the data too closely.\n"
      ]
    },
    {
      "metadata": {
        "id": "Y_IdpFBUYbjR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title  { run: \"auto\", vertical-output: true }\n",
        "clear_output()\n",
        "num_units = 1 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "\n",
        "model(\"ReLU\", num_units, 100, .001, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9rq34Cq1_VZN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initializing the Weights\n",
        "\n",
        "With logistic regression, we just initialized our weight matrix to 0's. With neural networks, though, if we intialized all of our weights to 0, then every single hidden unit would get updated the exact same way. It would be the equivalent of doing just logistic regression. Instead, we want to randomly set our weights to some small number around 0. Use the dropdown below to see the difference random intialization can make. "
      ]
    },
    {
      "metadata": {
        "id": "WLcdUzJ-Tjx-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title  { run: \"auto\", vertical-output: true }\n",
        "intialize_weights = \"randomly\" #@param [\"randomly\", \"zeros\"]\n",
        "\n",
        "if intialize_weights == \"randomly\":\n",
        "    model(\"tanh\", 100, num_it, .001, 1)\n",
        "else:\n",
        "    model(\"tanh\", 100, num_it, .001, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8FPNwtUFpHD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Learning Rate"
      ]
    },
    {
      "metadata": {
        "id": "zCTWuxUSAd2G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The learning rate is some small number we use to scale our derivatives when updating our weights and biases during gradient descent. Choosing a good learning rate can have a big impact on how our model trains. If our learning rate is too small, our model can take too long to optmize. If it is too big then we might keep overshooting our optimal weights.\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/0*QwE8M4MupSdqA3M4.png\" height=\"200px\"/>\n",
        "\n",
        "\n",
        "Use the dropdown below to try out a few different learning rates.\n",
        "\n",
        "**Some things to note**\n",
        "- How does the size of the learning rate affect the accuracy of the model?\n",
        "    - Is it a linear relationship?\n",
        "- How does it affect how quickly our model trains?\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "AmEyxao1Z5zg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title { run: \"auto\", vertical-output: true }\n",
        "clear_output()\n",
        "learning_rate = 0.00001 #@param [\"0.00001\", \"0.0001\", \"0.001\", \"0.01\", \"0.1\", \"1\", \"10\"] {type:\"raw\"}\n",
        "\n",
        "model(\"ReLU\", 100, 100, learning_rate, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5v9usM3aFt0D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Number of Training Iterations"
      ]
    },
    {
      "metadata": {
        "id": "gW4unFiHB9jt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The number of training iterations is the number of time we will do forward and backpropogation. Use the slider to try out different numbers of iterations.\n",
        "\n",
        "**Some things to note**\n",
        "- How does the number of iterations affect the accuracy of the model?\n",
        "    - Is it a linear realtionship?\n",
        "- How does it affect the training time?\n",
        "- If we did too many iterations what could you forsee happening?\n",
        "    - Hint: What happens when our model gets too good at predicting outputs for our training data?\n"
      ]
    },
    {
      "metadata": {
        "id": "IYasfg6mb_lE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title  { run: \"auto\", vertical-output: true }\n",
        "clear_output()\n",
        "num_it = 1 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "\n",
        "model(\"ReLU\", 100, num_it, .001, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}